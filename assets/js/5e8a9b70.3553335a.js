"use strict";(self.webpackChunkpython=self.webpackChunkpython||[]).push([[8816],{1684:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"python-guide/Multiprocessing/Intro","title":"Concurrency Paradigms","description":"Concurrency is a fundamental concept in programming that allows multiple tasks to be executed simultaneously, enhancing the efficiency and responsiveness of applications. Python offers several paradigms to achieve concurrency, each with its unique characteristics, advantages, and use cases. This documentation delves into three primary concurrency paradigms in Python: Asynchronous Programming, Multithreading, and Multiprocessing. By understanding their differences and applications, developers can optimize their Python applications for various workloads.","source":"@site/docs/python-guide/12_Multiprocessing/01_Intro.md","sourceDirName":"python-guide/12_Multiprocessing","slug":"/python-guide/Multiprocessing/Intro","permalink":"/Python/docs/python-guide/Multiprocessing/Intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/python-guide/12_Multiprocessing/01_Intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"guideSidebar","previous":{"title":"Multiprocessing","permalink":"/Python/docs/category/multiprocessing"},"next":{"title":"Multiprocessing in Python","permalink":"/Python/docs/python-guide/Multiprocessing/Processes"}}');var r=s(4848),t=s(8453);const a={},o="Concurrency Paradigms",c={},l=[{value:"Introduction",id:"introduction",level:2},{value:"Asynchronous Programming",id:"asynchronous-programming",level:2},{value:"Key Characteristics",id:"key-characteristics",level:3},{value:"Advantages",id:"advantages",level:3},{value:"Example Code",id:"example-code",level:3},{value:"Advanced Example: Concurrent Asynchronous Tasks",id:"advanced-example-concurrent-asynchronous-tasks",level:3},{value:"Multithreading",id:"multithreading",level:2},{value:"Key Characteristics",id:"key-characteristics-1",level:3},{value:"Advantages",id:"advantages-1",level:3},{value:"Disadvantages",id:"disadvantages",level:3},{value:"Example Code",id:"example-code-1",level:3},{value:"Advanced Example: Using ThreadPoolExecutor",id:"advanced-example-using-threadpoolexecutor",level:3},{value:"Multiprocessing",id:"multiprocessing",level:2},{value:"Key Characteristics",id:"key-characteristics-2",level:3},{value:"Advantages",id:"advantages-2",level:3},{value:"Disadvantages",id:"disadvantages-1",level:3},{value:"Example Code",id:"example-code-2",level:3},{value:"Advanced Example: CPU-bound Computation with Multiprocessing",id:"advanced-example-cpu-bound-computation-with-multiprocessing",level:3},{value:"Comparison of Concurrency Paradigms",id:"comparison-of-concurrency-paradigms",level:2},{value:"Summary",id:"summary",level:3},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"concurrency-paradigms",children:"Concurrency Paradigms"})}),"\n",(0,r.jsx)(n.p,{children:"Concurrency is a fundamental concept in programming that allows multiple tasks to be executed simultaneously, enhancing the efficiency and responsiveness of applications. Python offers several paradigms to achieve concurrency, each with its unique characteristics, advantages, and use cases. This documentation delves into three primary concurrency paradigms in Python: Asynchronous Programming, Multithreading, and Multiprocessing. By understanding their differences and applications, developers can optimize their Python applications for various workloads."}),"\n",(0,r.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:"In this tutorial, we will explore the concepts of asynchronous programming, multithreading, and multiprocessing in Python. This foundational knowledge is essential for the efficient and effective utilization of Python\u2019s concurrency capabilities. The following sections provide an in-depth comparison of these paradigms, followed by practical code examples to illustrate their usage."}),"\n",(0,r.jsx)(n.h2,{id:"asynchronous-programming",children:"Asynchronous Programming"}),"\n",(0,r.jsx)(n.p,{children:"Asynchronous programming allows for non-blocking execution, where tasks can pause (e.g., waiting for an I/O operation to complete) and resume without blocking the main thread. This is particularly useful for I/O-bound tasks, such as network requests, file I/O, or database operations."}),"\n",(0,r.jsx)(n.h3,{id:"key-characteristics",children:"Key Characteristics"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Single-threaded"}),": Operates within a single thread, avoiding the complexities of thread management."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Non-blocking"}),": Tasks can yield control during operations that would otherwise block, allowing other tasks to proceed."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Managed by the Code"}),": Concurrency is handled at the application level using constructs like ",(0,r.jsx)(n.code,{children:"async"})," and ",(0,r.jsx)(n.code,{children:"await"}),", rather than relying on the operating system."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"advantages",children:"Advantages"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Efficiency"}),": Minimizes overhead associated with thread creation and context switching."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Scalability"}),": Handles a large number of concurrent tasks with minimal resource consumption."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simplicity"}),": Avoids issues related to thread synchronization and shared state."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-code",children:"Example Code"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import asyncio\n\nasync def fetch_data():\n    print("Start fetching data")\n    await asyncio.sleep(2)  # Simulating an I/O operation with sleep\n    print("Done fetching data")\n    return "Data"\n\nasync def main():\n    data = await fetch_data()\n    print(f"Fetched: {data}")\n\n# Run the asynchronous event loop\nasyncio.run(main())\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Explanation:"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsxs)(n.strong,{children:[(0,r.jsx)(n.code,{children:"fetch_data"})," Function"]}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Declared with ",(0,r.jsx)(n.code,{children:"async def"}),", making it a coroutine."]}),"\n",(0,r.jsxs)(n.li,{children:["Uses ",(0,r.jsx)(n.code,{children:"await asyncio.sleep(2)"})," to simulate a non-blocking I/O operation."]}),"\n",(0,r.jsx)(n.li,{children:"Returns a string after the simulated delay."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsxs)(n.strong,{children:[(0,r.jsx)(n.code,{children:"main"})," Function"]}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Awaits the result of ",(0,r.jsx)(n.code,{children:"fetch_data"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Prints the fetched data."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Running the Event Loop"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"asyncio.run(main())"})," starts the event loop and executes the ",(0,r.jsx)(n.code,{children:"main"})," coroutine."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Sample Output:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Start fetching data\nDone fetching data\nFetched: Data\n"})}),"\n",(0,r.jsx)(n.h3,{id:"advanced-example-concurrent-asynchronous-tasks",children:"Advanced Example: Concurrent Asynchronous Tasks"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import asyncio\n\nasync def fetch_data(task_id, delay):\n    print(f"Task {task_id}: Start fetching data")\n    await asyncio.sleep(delay)\n    print(f"Task {task_id}: Done fetching data")\n    return f"Data from task {task_id}"\n\nasync def main():\n    tasks = [\n        fetch_data(1, 2),\n        fetch_data(2, 3),\n        fetch_data(3, 1)\n    ]\n    results = await asyncio.gather(*tasks)\n    for result in results:\n        print(result)\n\nasyncio.run(main())\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Explanation:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Concurrent Execution"}),": Multiple ",(0,r.jsx)(n.code,{children:"fetch_data"})," coroutines are created and run concurrently using ",(0,r.jsx)(n.code,{children:"asyncio.gather"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Efficient Task Management"}),": The event loop manages task switching, allowing tasks to run without waiting for others to complete."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Sample Output:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Task 1: Start fetching data\nTask 2: Start fetching data\nTask 3: Start fetching data\nTask 3: Done fetching data\nTask 1: Done fetching data\nTask 2: Done fetching data\nData from task 1\nData from task 2\nData from task 3\n"})}),"\n",(0,r.jsx)(n.h2,{id:"multithreading",children:"Multithreading"}),"\n",(0,r.jsx)(n.p,{children:"Multithreading allows multiple threads to run concurrently within a single process. This paradigm is beneficial for I/O-bound tasks, enabling tasks to wait for I/O operations without blocking the entire program. However, due to Python's Global Interpreter Lock (GIL), multithreading does not provide true parallelism for CPU-bound tasks."}),"\n",(0,r.jsx)(n.h3,{id:"key-characteristics-1",children:"Key Characteristics"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multiple Threads"}),": Executes multiple threads concurrently within the same process."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Shared Memory Space"}),": Threads share the same memory space, facilitating easy data sharing but introducing potential synchronization issues."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GIL Constraints"}),": The GIL restricts the execution of Python bytecode to one thread at a time, limiting performance gains for CPU-bound tasks."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"advantages-1",children:"Advantages"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"I/O-bound Task Efficiency"}),": Enhances performance for tasks that spend time waiting for I/O operations."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simpler Data Sharing"}),": Shared memory allows easy communication between threads without the need for inter-process communication mechanisms."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lightweight"}),": Threads are lighter than processes, consuming fewer system resources."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"disadvantages",children:"Disadvantages"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GIL Limitation"}),": Limits performance improvements for CPU-bound tasks."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synchronization Complexity"}),": Shared memory can lead to race conditions and requires careful synchronization using locks or other primitives."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-code-1",children:"Example Code"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import threading\nimport time\n\ndef print_numbers():\n    for i in range(5):\n        time.sleep(1)\n        print(i)\n\ndef print_letters():\n    for letter in 'ABCDE':\n        time.sleep(1.5)\n        print(letter)\n\n# Creating threads\nthread1 = threading.Thread(target=print_numbers)\nthread2 = threading.Thread(target=print_letters)\n\n# Starting threads\nthread1.start()\nthread2.start()\n\n# Waiting for both threads to finish\nthread1.join()\nthread2.join()\n\nprint(\"Both threads have completed execution.\")\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Explanation:"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsxs)(n.strong,{children:[(0,r.jsx)(n.code,{children:"print_numbers"})," Function"]}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Prints numbers from 0 to 4 with a 1-second delay between each."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsxs)(n.strong,{children:[(0,r.jsx)(n.code,{children:"print_letters"})," Function"]}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Prints letters from 'A' to 'E' with a 1.5-second delay between each."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Thread Creation and Execution"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Two threads are created targeting the respective functions."}),"\n",(0,r.jsx)(n.li,{children:"Threads are started, allowing both functions to run concurrently."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"join()"})," ensures the main thread waits for both threads to complete before proceeding."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Sample Output:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"0\nA\n1\n2\nB\n3\nC\n4\nD\nE\nBoth threads have completed execution.\n"})}),"\n",(0,r.jsx)(n.h3,{id:"advanced-example-using-threadpoolexecutor",children:"Advanced Example: Using ThreadPoolExecutor"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from concurrent.futures import ThreadPoolExecutor\nimport time\n\ndef task(name, duration):\n    print(f"Task {name}: Starting")\n    time.sleep(duration)\n    print(f"Task {name}: Completed")\n    return f"Result from {name}"\n\ndef main():\n    with ThreadPoolExecutor(max_workers=3) as executor:\n        futures = [\n            executor.submit(task, "A", 2),\n            executor.submit(task, "B", 3),\n            executor.submit(task, "C", 1)\n        ]\n        for future in futures:\n            result = future.result()\n            print(result)\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Explanation:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ThreadPoolExecutor"}),": Manages a pool of threads, simplifying thread management and reuse."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Submitting Tasks"}),": Three tasks with varying durations are submitted to the executor."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Retrieving Results"}),": ",(0,r.jsx)(n.code,{children:"future.result()"})," retrieves the result of each task once completed."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Sample Output:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Task A: Starting\nTask B: Starting\nTask C: Starting\nTask C: Completed\nResult from C\nTask A: Completed\nResult from A\nTask B: Completed\nResult from B\n"})}),"\n",(0,r.jsx)(n.h2,{id:"multiprocessing",children:"Multiprocessing"}),"\n",(0,r.jsx)(n.p,{children:"Multiprocessing involves running multiple processes in parallel, each with its own Python interpreter and memory space. This paradigm is particularly useful for CPU-bound tasks, as it bypasses the GIL, allowing true parallel execution across multiple CPU cores."}),"\n",(0,r.jsx)(n.h3,{id:"key-characteristics-2",children:"Key Characteristics"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multiple Processes"}),": Executes tasks in separate processes, each with its own memory space."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"True Parallelism"}),": Achieves parallel execution on multi-core systems without GIL restrictions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Inter-process Communication (IPC)"}),": Requires mechanisms like pipes or queues for data sharing between processes."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"advantages-2",children:"Advantages"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CPU-bound Task Efficiency"}),": Enables true parallelism, significantly improving performance for compute-intensive operations."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Independent Memory Space"}),": Processes do not share memory, reducing the risk of data corruption and simplifying debugging."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Bypasses GIL"}),": Each process has its own GIL, eliminating the constraints faced by multithreading for CPU-bound tasks."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"disadvantages-1",children:"Disadvantages"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Higher Resource Consumption"}),": Processes are heavier than threads, consuming more system resources."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Complex IPC"}),": Sharing data between processes is more complex and may require serialization."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Slower Startup"}),": Creating processes has a higher overhead compared to creating threads."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-code-2",children:"Example Code"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from multiprocessing import Process\nimport os\n\ndef print_process_info(name):\n    print(f'Process name: {name}, Process ID: {os.getpid()}')\n\nif __name__ == '__main__':\n    processes = []\n    for i in range(5):\n        process = Process(target=print_process_info, args=(f'Process-{i}',))\n        processes.append(process)\n        process.start()\n\n    for process in processes:\n        process.join()\n    \n    print(\"All processes have completed execution.\")\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Explanation:"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsxs)(n.strong,{children:[(0,r.jsx)(n.code,{children:"print_process_info"})," Function"]}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Prints the name and process ID of each process."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Process Creation and Execution"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Five processes are created, each targeting the ",(0,r.jsx)(n.code,{children:"print_process_info"})," function with a unique name."]}),"\n",(0,r.jsx)(n.li,{children:"Processes are started, running concurrently."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"join()"})," ensures the main process waits for all child processes to complete before proceeding."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Sample Output:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Process name: Process-0, Process ID: 12345\nProcess name: Process-1, Process ID: 12346\nProcess name: Process-2, Process ID: 12347\nProcess name: Process-3, Process ID: 12348\nProcess name: Process-4, Process ID: 12349\nAll processes have completed execution.\n"})}),"\n",(0,r.jsx)(n.h3,{id:"advanced-example-cpu-bound-computation-with-multiprocessing",children:"Advanced Example: CPU-bound Computation with Multiprocessing"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from multiprocessing import Process, current_process\nimport math\nimport time\n\ndef compute_prime_factors(n):\n    print(f"{current_process().name} started computing prime factors of {n}")\n    factors = []\n    # Simple algorithm for demonstration\n    for i in range(2, int(math.sqrt(n)) + 1):\n        while n % i == 0:\n            factors.append(i)\n            n = n // i\n    if n > 1:\n        factors.append(n)\n    time.sleep(2)  # Simulate computation delay\n    print(f"{current_process().name} completed: {factors}")\n    return factors\n\nif __name__ == \'__main__\':\n    numbers = [112272535095293, 112582705942171, 115280095190773]\n    processes = []\n    for number in numbers:\n        process = Process(target=compute_prime_factors, args=(number,), name=f"Process-{number}")\n        processes.append(process)\n        process.start()\n\n    for process in processes:\n        process.join()\n    \n    print("All computations have been completed.")\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Explanation:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CPU-bound Task"}),": Computing prime factors is CPU-intensive, making it suitable for multiprocessing."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Process Naming"}),": Each process is named uniquely for clarity in output."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simulated Delay"}),": ",(0,r.jsx)(n.code,{children:"time.sleep(2)"})," represents a delay to mimic computation time."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Sample Output:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Process-112272535095293 started computing prime factors of 112272535095293\nProcess-112582705942171 started computing prime factors of 112582705942171\nProcess-115280095190773 started computing prime factors of 115280095190773\nProcess-112272535095293 completed: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\nProcess-112582705942171 completed: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\nProcess-115280095190773 completed: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\nAll computations have been completed.\n"})}),"\n",(0,r.jsx)(n.h2,{id:"comparison-of-concurrency-paradigms",children:"Comparison of Concurrency Paradigms"}),"\n",(0,r.jsx)(n.p,{children:"Understanding the distinctions between asynchronous programming, multithreading, and multiprocessing is crucial for selecting the appropriate concurrency model based on the application's requirements."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Feature"}),(0,r.jsx)(n.th,{children:"Asynchronous Programming"}),(0,r.jsx)(n.th,{children:"Multithreading"}),(0,r.jsx)(n.th,{children:"Multiprocessing"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Execution Model"})}),(0,r.jsx)(n.td,{children:"Single-threaded, non-blocking"}),(0,r.jsx)(n.td,{children:"Multiple threads, concurrency"}),(0,r.jsx)(n.td,{children:"Multiple processes, parallelism"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Suitable For"})}),(0,r.jsx)(n.td,{children:"I/O-bound tasks"}),(0,r.jsx)(n.td,{children:"I/O-bound tasks"}),(0,r.jsx)(n.td,{children:"CPU-bound tasks"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"GIL Impact"})}),(0,r.jsx)(n.td,{children:"Not impacted"}),(0,r.jsx)(n.td,{children:"Restricted by GIL"}),(0,r.jsx)(n.td,{children:"Not impacted (each process has its own GIL)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Memory Space"})}),(0,r.jsx)(n.td,{children:"Shared"}),(0,r.jsx)(n.td,{children:"Shared"}),(0,r.jsx)(n.td,{children:"Separate"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Overhead"})}),(0,r.jsx)(n.td,{children:"Low"}),(0,r.jsx)(n.td,{children:"Low to moderate"}),(0,r.jsx)(n.td,{children:"High"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Complexity"})}),(0,r.jsx)(n.td,{children:"Moderate (requires understanding of async/await)"}),(0,r.jsx)(n.td,{children:"Moderate (requires synchronization)"}),(0,r.jsx)(n.td,{children:"High (requires IPC mechanisms)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Scalability"})}),(0,r.jsx)(n.td,{children:"High for I/O-bound tasks"}),(0,r.jsx)(n.td,{children:"Limited by GIL for CPU-bound tasks"}),(0,r.jsx)(n.td,{children:"High for CPU-bound tasks"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"summary",children:"Summary"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Asynchronous Programming"})," is ideal for applications that involve a high number of I/O-bound operations, such as web servers or network applications. It allows efficient task management without the overhead of multiple threads or processes."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Multithreading"})," is suitable for scenarios where tasks are I/O-bound but benefit from concurrent execution, such as handling multiple client connections in a server. However, its effectiveness is limited for CPU-bound tasks due to the GIL."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Multiprocessing"})," is the go-to solution for CPU-bound tasks that require true parallelism, such as data processing, scientific computations, or machine learning model training. It bypasses the GIL by running separate processes, each with its own Python interpreter."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,r.jsx)(n.p,{children:"Understanding the differences between asynchronous programming, multithreading, and multiprocessing is crucial for optimizing the performance of Python applications. Each concurrency paradigm offers unique advantages tailored to specific types of tasks:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Asynchronous Programming"})," excels in handling I/O-bound tasks without blocking the main thread, enabling efficient and scalable applications."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Multithreading"})," is effective for I/O-bound tasks that benefit from concurrent execution but is constrained by the GIL for CPU-bound operations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Multiprocessing"})," provides true parallelism by running multiple processes, each with its own memory space and GIL instance, making it ideal for CPU-bound tasks."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"By leveraging the appropriate concurrency model, developers can enhance the efficiency, responsiveness, and scalability of their Python applications. In subsequent lessons, we will delve deeper into practical applications and advanced techniques for utilizing these concurrency paradigms, enabling you to harness the full power of Python's concurrency capabilities."})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>o});var i=s(6540);const r={},t=i.createContext(r);function a(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);